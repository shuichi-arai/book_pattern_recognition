----------------------------------------------------------------------------------------------------
第5章「パラメトリックな学習」

./1.MaximumLikelihood.py    [sample] 5.3節「最尤推定」の例題

----------------------------------------------------------------------------------------------------

あるクラスに属するデータD={x_1, x_2, ... x_N}が与えられたときに，
このクラスのクラス依存確率密度を推定することを考えるのがこの章の目的でした．
推定方法は最尤推定とベイズ推定がありますが，ここでは，最尤推定について考えます．
与えられたデータの生起確率が正規分布に従っていると仮定すれば
正規分布のパラメータ(μ,σ^2)をデータDから学習できれば，クラス依存確率密度を推定できます．

最適なパラメータ(μ,σ^2)を定めるのが目的ですが，最適を決める尺度は「尤度」を用います．

尤度は,
1) あるパラメータ(μ_0 ,σ_0 ^2)を決め
2) これにより定まるクラス依存確率密度p(x|ω)に学習データDから１つのx_nを代入して確率密度値を求め
3) 全ての学習データDから式(5.7)のように確率密度値の積を求めたものです．

すなわち，データDがパラメータ(μ,σ^2)で定まるp(x|ω)にどれだけ適合しているのかを示していて，
テキストにも書いたように，「データDに関するパラメータ(μ,σ^2)の尤度（尤もらしさ）」を表します．

最尤推定とは，尤度が最大になるようなパラメータ(μ,σ^2)を推定することです．

------------------
プログラムの使い方
------------------
1. [操作]データDはd1〜d10までの10種類用意してあり，画面右下のRadio buttonで選択できます．
2. データDを選択すると，データx_nが右上のグラフに赤い点として表示されます．
3. 同時にさまざまなパラメータ(μ,σ^2)に対して尤度を計算し，左上のグラフにHeat mapで表示します．
   これには時間がちょっとかかります．
4. さらにこのHeat mapの最大値（最尤推定値）MLを緑丸で表示します．
5. [操作]では，Sliderであなたがパラメータ(μ,σ^2)を指定してください．
6. すると，その値が左上のグラフに表示され，
7. あなたが指定したパラメータで表現されるクラス依存確率密度関数が右上に表示されます．
8. そのときのDに関する尤度が数値として表示されます．
9. 予め算出したMLの値も表示しておきました．

[操作] Reset buttonで初期パラメータに戻ります．
[操作] Save buttonでその時の画面を画像として保存します．
[操作] Quit buttonで終了します．

